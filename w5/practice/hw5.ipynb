{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93142aa5-cd63-4d69-b0f3-5574ad5b6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52bf2b-08e0-4427-b89a-d141afa3fabd",
   "metadata": {},
   "source": [
    "### Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e47128c-c490-46bb-8d94-e65884fac610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 00:18:47--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T001847Z&X-Amz-Expires=300&X-Amz-Signature=a795e63ce3c1672eb5d0492ba5f50f3255f68e1df1b8bbc60cf8963315dc8a88&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-04 00:18:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T001847Z&X-Amz-Expires=300&X-Amz-Signature=a795e63ce3c1672eb5d0492ba5f50f3255f68e1df1b8bbc60cf8963315dc8a88&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  52.2MB/s    in 0.4s    \n",
      "\n",
      "2024-03-04 00:18:47 (52.2 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60ff08a-dbd5-4042-b2f4-d70d470f404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispatching_base_num,pickup_datetime,dropOff_datetime,PUlocationID,DOlocationID,SR_Flag,Affiliated_base_number\n",
      "B00009,2019-10-01 00:23:00,2019-10-01 00:35:00,264,264,,B00009\n",
      "B00013,2019-10-01 00:11:29,2019-10-01 00:13:22,264,264,,B00013\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! zcat fhv_tripdata_2019-10.csv.gz | head -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10652100-969e-4afd-9116-50482813e6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494\n"
     ]
    }
   ],
   "source": [
    "! zcat fhv_tripdata_2019-10.csv.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea51b1c6-f60e-4cce-a2ce-9a5f8f69a37f",
   "metadata": {},
   "source": [
    "### Init Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793cc5e1-78ce-4da5-90ab-8964351a8fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/04 00:23:58 WARN Utils: Your hostname, codespaces-fb2ab8 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "24/03/04 00:23:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/04 00:23:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1ade9-71d0-49c8-b481-52fe6512f296",
   "metadata": {},
   "source": [
    "### Question 1: Install Spark and PySpark\n",
    "\n",
    "Answer: 3.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "307f5223-055d-4875-a75d-62d7e7268b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af8bfc-adbd-4974-9709-fb67add61d6a",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5692212c-dfa6-44f4-862e-295eef52ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cbc48c7-49a6-4ce2-acac-2e1176abd1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropOff_datetime: string (nullable = true)\n",
      " |-- PUlocationID: string (nullable = true)\n",
      " |-- DOlocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1375e3b-f1d5-4d6e-8b01-b512e2789613",
   "metadata": {},
   "source": [
    "### Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9948584e-d24c-4db9-a6fb-49ade28bcd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7)\n",
      "dispatching_base_num       object\n",
      "pickup_datetime            object\n",
      "dropOff_datetime           object\n",
      "PUlocationID                int64\n",
      "DOlocationID                int64\n",
      "SR_Flag                   float64\n",
      "Affiliated_base_number     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_pd = pd.read_csv('fhv_tripdata_2019-10.csv.gz', compression='gzip', nrows=2)\n",
    "print(df_pd.shape)\n",
    "print(df_pd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef0bca7e-6c3d-4706-8026-2844c2e73a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0               B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1               B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "\n",
       "   PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           264           264      NaN                 B00009  \n",
       "1           264           264      NaN                 B00013  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ddf4a68-eaae-4c3d-b9e5-faebdc6359c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', LongType(), True), StructField('DOlocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "df_pd.iteritems = df_pd.items\n",
    "spark.createDataFrame(df_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6a8e939-3d21-49d0-a24a-28b6914ea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PUlocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOlocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbae982-15c7-4613-868f-f047ffb0a125",
   "metadata": {},
   "source": [
    "### Reload Data with Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "662cd26d-ced7-4b68-af93-ca85971924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7291f568-d7ff-4cab-bbfa-a2c6d0a77b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1897493"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7f632ee-902a-403b-9a9f-4c826fb6cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02653|2019-10-08 13:53:21|2019-10-08 13:56:24|         264|         247|   null|                B02653|\n",
      "|              B00837|2019-10-12 08:20:51|2019-10-12 08:32:35|         264|         264|   null|                B00837|\n",
      "|              B01315|2019-10-05 15:13:04|2019-10-05 15:19:48|         264|          74|   null|                B01315|\n",
      "|              B00789|2019-10-23 00:56:36|2019-10-23 01:33:24|         264|         264|   null|                B00789|\n",
      "|              B00937|2019-10-18 11:03:47|2019-10-18 11:22:46|         264|          75|   null|                B00937|\n",
      "|              B03060|2019-10-18 16:31:09|2019-10-18 16:35:05|         264|          22|   null|                B02825|\n",
      "|              B03033|2019-10-20 02:59:38|2019-10-20 03:04:52|         264|          36|   null|                B03033|\n",
      "|              B01231|2019-10-11 13:19:24|2019-10-11 14:04:19|         264|          17|   null|                B02872|\n",
      "|              B02688|2019-10-02 10:59:00|2019-10-02 11:34:46|         264|         107|   null|                B02688|\n",
      "|              B01029|2019-10-10 14:45:00|2019-10-10 15:47:00|         264|         264|   null|                B01029|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9cc8463-9359-479d-b5b8-801ab258d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67b85a-27c5-4a0d-b3ed-1496ffe45321",
   "metadata": {},
   "source": [
    "### Question 2: FHV October 2019\n",
    "\n",
    "\n",
    "- Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "- Find the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)\n",
    "\n",
    "Answer: 6MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e1e7c4a-ddc7-48b1-81eb-8c3e421de096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "362a6c67-d273-427d-8e38-fe253fb3d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca5febae-345b-485e-a2e5-af9888864079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\n",
      "-rw-r--r-- 1 codespace codespace    0 Mar  4 00:39 _SUCCESS\n",
      "-rw-r--r-- 1 codespace codespace 6.4M Mar  4 00:39 part-00000-e97bac8e-c6bb-4de6-ad22-c1b5f0d7e71a-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.4M Mar  4 00:39 part-00001-e97bac8e-c6bb-4de6-ad22-c1b5f0d7e71a-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.4M Mar  4 00:39 part-00002-e97bac8e-c6bb-4de6-ad22-c1b5f0d7e71a-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.4M Mar  4 00:39 part-00003-e97bac8e-c6bb-4de6-ad22-c1b5f0d7e71a-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.4M Mar  4 00:39 part-00004-e97bac8e-c6bb-4de6-ad22-c1b5f0d7e71a-c000.snappy.parquet\n",
      "-rw-r--r-- 1 codespace codespace 6.4M Mar  4 00:39 part-00005-e97bac8e-c6bb-4de6-ad22-c1b5f0d7e71a-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls -lh ./fhv/2019/10/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d337cc7-23e2-4351-afc5-92bb79ef47bb",
   "metadata": {},
   "source": [
    "### Register SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a01e71e-98c0-4df5-8f3d-1ff81b447143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3a890-6fbc-42d2-b260-c0ec5fd3a590",
   "metadata": {},
   "source": [
    "### Question 3: Count records\n",
    "\n",
    "How many taxi trips were there on the 15th of October? Consider only trips that started on the 15th of October.\n",
    "\n",
    "Answer:  62610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "574b78db-1a11-4e09-a4e7-288afa39f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df.pickup_datetime >= '2019-10-15 00:00:00') & (df.pickup_datetime < '2019-10-16 00:00:00')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b244129-1255-44cf-a740-c1f184f943f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   62610|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        count(1)\n",
    "    FROM\n",
    "        trips_data\n",
    "    WHERE \n",
    "         pickup_datetime >= '2019-10-15 00:00:00'\n",
    "         AND pickup_datetime < '2019-10-16 00:00:00'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c97fe-ae8e-4109-bd34-5afb89bd8c70",
   "metadata": {},
   "source": [
    "### Question 4: Longest trip for each day\n",
    "\n",
    "Answer: 631,152.50 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d66662ef-91d2-4376-b806-7c6d3f42516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+\n",
      "|   dropOff_datetime|    pickup_datetime|      duration_hr|\n",
      "+-------------------+-------------------+-----------------+\n",
      "|2091-10-11 18:30:00|2019-10-11 18:00:00|         631152.5|\n",
      "|2091-10-28 09:30:00|2019-10-28 09:00:00|         631152.5|\n",
      "|2029-11-01 00:13:00|2019-10-31 23:46:33|87672.44083333333|\n",
      "|2027-10-01 21:45:23|2019-10-01 21:43:42|70128.02805555555|\n",
      "|2020-10-18 00:00:00|2019-10-17 14:00:00|           8794.0|\n",
      "+-------------------+-------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        dropOff_datetime, \n",
    "        pickup_datetime,\n",
    "        (bigint(dropOff_datetime) - bigint(pickup_datetime)) / (60*60) AS duration_hr\n",
    "    FROM\n",
    "        trips_data\n",
    "    ORDER BY duration_hr DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e70c57-c6fe-4f28-b997-22beba241d7e",
   "metadata": {},
   "source": [
    "### Question 5: User Interface\n",
    "\n",
    "Answer: Spark’s User Interface which shows the application's dashboard runs on port 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773e721-c719-43ad-8da0-9b016079ab0b",
   "metadata": {},
   "source": [
    "### Load Zone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3341b33b-b14b-4c49-891b-27698c237171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 01:05:37--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.196.184, 52.217.99.182, 52.217.133.136, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.196.184|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-04 01:05:37 (55.9 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aadf2e11-f6f7-4526-b69a-49836d7b1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fcb7e329-262d-4ba0-bc2c-f1fff92deeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61273581-9f83-4fa8-a65f-622a3bc59e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8db010ae-844a-493c-9b9e-075148cf2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df.write.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de2d3321-5377-46ed-82e4-4a0db480147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df.registerTempTable('zone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef73bb8-4bda-4a86-a272-217983fa22f1",
   "metadata": {},
   "source": [
    "### Question 6: Least frequent pickup location zone\n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?\n",
    "\n",
    "Answer: Jamaica Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd311809-3b42-4e77-9a4f-33848120f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|         pickup_zone|cnt|\n",
      "+--------------------+---+\n",
      "|         Jamaica Bay|  1|\n",
      "|Governor's Island...|  2|\n",
      "| Green-Wood Cemetery|  5|\n",
      "|       Broad Channel|  8|\n",
      "|     Highbridge Park| 14|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        Zone pickup_zone, COUNT(1) cnt\n",
    "    FROM\n",
    "        trips_data a\n",
    "        INNER JOIN zone b\n",
    "            ON a.PUlocationID = b.LocationID\n",
    "    GROUP BY Zone\n",
    "    ORDER BY cnt ASC\n",
    "    LIMIT 5\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
